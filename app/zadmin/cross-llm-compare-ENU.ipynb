{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030d3b4f-1a6b-46a9-9089-c46d7918307f",
   "metadata": {},
   "source": [
    "## cross-LLM model comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb92c5d-f27e-4c79-bf7b-231c7cdfc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_models = [\n",
    "    \"qwen2.5\", \"llama3.1\", \"mistral\", \"nemotron-mini\",\n",
    "    \"phi3.5\", \"gemma2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e316689-4126-4114-a50a-e3ddee1b30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import ollama\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0315667a-1339-4f0a-b63c-43d60c7cff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'```json\\s*(.*?)\\s*```'\n",
    "file_log = \"cross-llm-compare.log\"\n",
    "zi =  \"person\" # \"字\"  # \"心\"\n",
    "\n",
    "lang = \"ENU\"\n",
    "try:\n",
    "    prompt_zi = LLM_PROMPT_ZI_DICT[lang]\n",
    "except Exception as e:\n",
    "    raise Exception(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd765a5-caa7-4461-a8d8-7cb242ef4f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling qwen2.5 on person ...\n",
      "[2024-09-21 12:15:31.842667] Completed ENU - person - qwen2.5 in 116.013 sec\n",
      "Calling llama3.1 on person ...\n",
      "[2024-09-21 12:17:27.856358] Completed ENU - person - llama3.1 in 156.096 sec\n",
      "Calling mistral on person ...\n",
      "[2024-09-21 12:20:03.953041] Completed ENU - person - mistral in 235.236 sec\n",
      "Calling nemotron-mini on person ...\n",
      "[2024-09-21 12:23:59.189920] Completed ENU - person - nemotron-mini in 77.266 sec\n",
      "Calling phi3.5 on person ...\n",
      "[2024-09-21 12:25:16.457514] Completed ENU - person - phi3.5 in 116.952 sec\n",
      "Calling gemma2 on person ...\n",
      "[2024-09-21 12:27:13.410975] Completed ENU - person - gemma2 in 242.190 sec\n"
     ]
    }
   ],
   "source": [
    "for model_name in llm_models:\n",
    "    fp = Path(f\"./llm_models/{lang}\") / f\"{lang}-{zi}-{model_name}-1.txt\"    \n",
    "    if fp.exists():\n",
    "        log_msg(f\"SKIP {zi} - {model_name} : Already processed - {fp} \", file_log)\n",
    "        continue\n",
    "\n",
    "    print(f\"Calling '{model_name}' on '{zi}' ...\")\n",
    "    \n",
    "    ts_now = datetime.now()\n",
    "    ts_1 = time()\n",
    "    try:\n",
    "        resp = ollama.generate(model=model_name, prompt=prompt_zi.format(zi=zi))\n",
    "    except Exception as e:\n",
    "        log_msg(f\"[ERROR] {zi} - {model_name} : Failed to call ollama.generate()\", file_log)\n",
    "        continue\n",
    "        \n",
    "    ts_2 = time()\n",
    "    del_t = ts_2 - ts_1\n",
    "    del_t_str = f\"{del_t:.3f}\"\n",
    "    json_raw = resp.get('response', \"\")\n",
    "    if not json_raw: \n",
    "        log_msg(f\"[ERROR] No LLM response: {zi} - {model_name}\", file_log)\n",
    "        continue\n",
    "\n",
    "    log_msg(f\"[{str(ts_now)}] Completed {lang} - {zi} - {model_name} in {del_t_str} sec\")\n",
    "    with open(fp, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json_raw)\n",
    "\n",
    "    \n",
    "    # match = re.search(pattern, json_raw, re.DOTALL)\n",
    "\n",
    "    # if match:\n",
    "    #     json_string = match.group(1)\n",
    "    #     if not json_string:\n",
    "    #         log_msg(f\"[WARN] No JSON extracted: {zi}\")\n",
    "    #         continue\n",
    "            \n",
    "    #     with open(fp, \"w\", encoding=\"utf-8\") as f:\n",
    "    #         f.write(json_string)\n",
    "    # else:\n",
    "    #     log_msg(f\"[ERROR] No JSON extracted: {zi}\", file_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae53ff6-1e2c-412d-910a-c929486a1d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb713c7-aa48-4f42-8fd0-c18dc850a835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
